{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# DO NOT EDIT THIS NOTEBOOK\n",
    "# It generates a report to verify your submission\n",
    "import logging, sys, os\n",
    "logging.disable(sys.maxsize)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import solution\n",
    "import time\n",
    "start_verify = time.time()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "import inspect\n",
    "from IPython.core import page\n",
    "page.page = print\n",
    "\n",
    "grades = []\n",
    "\n",
    "def shout(text, verbose=1):\n",
    "    \"\"\" Prints text in red. Just for fun.\n",
    "    \"\"\"\n",
    "    if verbose>0:\n",
    "        print('\\033[91m'+text+'\\x1b[0m')\n",
    "        \n",
    "def printSource(obj):\n",
    "    print(''.join(str(x) for x in inspect.getsourcelines(obj)[0]))\n",
    "        \n",
    "# Helper function to extract min/max from the learning curves\n",
    "def minMax(x):\n",
    "    return pd.Series(index=['min','max'],data=[x.min(),x.max()])\n",
    "\n",
    "def print_answer(ans):\n",
    "    output = \"\"\n",
    "    for line in ans.splitlines()[1:]:\n",
    "        output += line.strip() + \" \"\n",
    "    output += \"(length: \"+str(len(output))+\")\\n\"\n",
    "    print(output)\n",
    "        \n",
    "def run_evaluation(name, model_builder, data, base_dir, target_dir, train=True, \n",
    "                   generator=False, epochs=3, batch_size=32, steps_per_epoch=60, \n",
    "                   verbose=1, print_model=True, **kwargs):\n",
    "    \"\"\" Trains and evaluates the given model on the predefined train and test splits,\n",
    "    stores the trained model and learning curves. Also prints out a summary of the \n",
    "    model and plots the learning curves.\n",
    "    Keyword arguments:\n",
    "    name -- the name of the model to be stored, e.g. 'question_1_1.h5'\n",
    "    model_builder -- function that returns an (untrained) model. The model must \n",
    "                     have a 'fit' function that follows the Keras API. It can wrap\n",
    "                     a non-Keras model as long as the 'fit' function takes the \n",
    "                     same attributes and returns the learning curves (history).\n",
    "                     It also must have a 'summary' function that prints out a \n",
    "                     model summary, and a 'save' function that saves the model \n",
    "                     to disk. \n",
    "    data -- data split for evaluation. A tuple of either:\n",
    "            * Numpy arrays (X_train, X_val, y_train, y_val)\n",
    "            * A data generator and validation data (generator, X_val, y_val)\n",
    "    base_dir -- the directory to save or read models to/from\n",
    "    train -- whether or not the data should be trained. If False, the trained model\n",
    "             will be loaded from disk.\n",
    "    generator -- whether the data in given as a generator or not\n",
    "    epochs -- the number of epochs to train for\n",
    "    batch_size -- the batch size to train with\n",
    "    steps_per_epoch -- steps per epoch, in case a generator is used (ignored otherwise)\n",
    "    verbose -- verbosity level, 0: silent, 1: minimal,...\n",
    "    kwargs -- keyword arguments that should be passed to model_builder.\n",
    "              Not required, but may help you to adjust its behavior\n",
    "    \"\"\"\n",
    "    model = model_builder(**kwargs)\n",
    "    if not model:\n",
    "        shout(\"No model is returned by the model_builder\")\n",
    "        grades.append(\"0\")\n",
    "        return\n",
    "    if not hasattr(model, 'fit'):\n",
    "        shout(\"Model is not built correctly\")\n",
    "        return\n",
    "    learning_curves = {}\n",
    "    if train and not stop_training: # Train anew\n",
    "        shout(\"Model not trained? Skipping.\", verbose)\n",
    "    else: # Load from file\n",
    "        model = solution.load_model_from_file(base_dir, name)\n",
    "        if not model:\n",
    "            shout(\"Model not found\")\n",
    "            return\n",
    "        learning_curves = None\n",
    "        try:\n",
    "            learning_curves = pickle.load(open(os.path.join(base_dir, name+'.p'), \"rb\"))\n",
    "        except FileNotFoundError:\n",
    "            shout(\"Learning curves not found\")\n",
    "            return\n",
    "    # Report\n",
    "    lc = pd.DataFrame(learning_curves)\n",
    "    print(\"Max val score: {:.2f}%\".format(lc.iloc[:,3].max()*100))\n",
    "    grades.append(\"{:.2f}\".format(lc.iloc[:,3].max()*100))\n",
    "    lc.plot(lw=2,style=['b:','r:','b-','r-']);\n",
    "    plt.xlabel('epochs');\n",
    "    plt.show()\n",
    "    \n",
    "    if print_model:\n",
    "        print(model.summary())\n",
    "    plot_model(model, to_file=os.path.join(target_dir,name+'.png'), show_shapes=True, show_layer_names=False)\n",
    "        \n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Information Retrieval and Data Mining - Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: LAST_NAME, FIRST_NAME (YOUR_ID)\n"
     ]
    }
   ],
   "source": [
    "grades.append(solution.target_dir.split(os.sep)[-1])\n",
    "grades.append(solution.your_name)\n",
    "print(\"Student: {0} ({1})\".format(solution.your_name,solution.student_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1.1, Baseline (4p)\n",
    "- Dense network, at least 3 layers, shaped like a pyramid\n",
    "    - Last layer: 10 nodes, sigmoid. \n",
    "    - Loss: categorical cross-entropy. Metric: accuracy\n",
    "- No preprocessing, regularization. Get at least 70% accuracy.\n",
    "- Explain design decisions. Discuss performance.\n",
    "    - Does it overfit (large/growing gap between loss and val_loss)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n",
      "\u001b[91mNo model is returned by the model_builder\u001b[0m\n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mbuild_model_1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_answer(solution.answer_q_1_1)\n",
    "run_evaluation(\"model_1_1\", solution.build_model_1_1, solution.evaluation_split, solution.base_dir, \n",
    "               solution.target_dir, train=False)\n",
    "%psource solution.build_model_1_1\n",
    "if os.path.exists(os.path.join(solution.target_dir,'model_1_1.png')):\n",
    "    display(Image(os.path.join(solution.target_dir,'model_1_1.png'), width=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1.2, Preprocess (2p)\n",
    "- Convert images to greyscale, other preprocessing optional.\n",
    "    - Input shape should be (32,32,1)\n",
    "- Explain design decisions. Is it better? Why (not)? \n",
    "    - Color information is likely not so useful for classification. Greyscale makes the network smaller, less parameters to learn, less likely to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n",
      "\u001b[91mNo model is returned by the model_builder\u001b[0m\n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mbuild_model_1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_answer(solution.answer_q_1_2)\n",
    "run_evaluation(\"model_1_2\", solution.build_model_1_2, solution.evaluation_split, solution.base_dir, \n",
    "               solution.target_dir, train=False)\n",
    "%psource solution.build_model_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1.3, Tune (4p)\n",
    "- Regularize the model. What works best? \n",
    "    - Should consider batch normalization, dropout, l1/l2 regularization (or Nesterov)\n",
    "- Tune other hyperparameters (e.g. learning rate, batch size,...) as you see fit.\n",
    "    - At least consider tuning learning rate, ideally also momentum, decay, other optimizers \n",
    "- Explain your findings and final design decisions. Discuss the results.\n",
    "    - Should be better, at least it shouldn't overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n",
      "\u001b[91mNo model is returned by the model_builder\u001b[0m\n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mbuild_model_1_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_answer(solution.answer_q_1_3)\n",
    "run_evaluation(\"model_1_3\", solution.build_model_1_3, solution.evaluation_split, solution.base_dir, \n",
    "               solution.target_dir, train=False, print_model=False)\n",
    "%psource solution.build_model_1_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 2.1, ConvNet (7p)\n",
    "- Build a sequential ConvNet, get at least 90% accuracy.\n",
    "    - Conv2D layers, input shape (32,32,1)\n",
    "    - Consider using blocks of Conv2D layers with maxpooling in between\n",
    "    - Use zero-padding in Conv2D layers because the images are small\n",
    "    - At least one dense hidden layer and dense output layer (sigmoid)\n",
    "    - Consider adding batch normalization, dropout\n",
    "    - Consider small dropout rates in beginning, larger dropout rates later in network\n",
    "    - Consider other optimizers and tuning learning rate, momentum,...\n",
    "- Explain what you did and why (800 chars). Is it working well?\n",
    "    - Should be quite elaborate and sensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n",
      "\u001b[91mNo model is returned by the model_builder\u001b[0m\n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mbuild_model_2_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_answer(solution.answer_q_2_1)\n",
    "run_evaluation(\"model_2_1\", solution.build_model_2_1, solution.evaluation_split, solution.base_dir, \n",
    "               solution.target_dir, train=False)\n",
    "%psource solution.build_model_2_1\n",
    "if os.path.exists(os.path.join(solution.target_dir,'model_2_1.png')):\n",
    "    display(Image(os.path.join(solution.target_dir,'model_2_1.png'), width=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 2.2, Data Augmentation (3p)\n",
    "- Augment the preprocessed training data.\n",
    "    - Use small variations (small shifts up-down, left-right) of flips becasue the images are small\n",
    "    - Large shifts and rotations distort the image too much\n",
    "- Explain what you did and why. Discuss the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n",
      "\u001b[91mNo model is returned by the model_builder\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_answer(solution.answer_q_2_2)\n",
    "run_evaluation(\"model_2_2\", solution.build_model_2_1, solution.augmented_split, solution.base_dir, \n",
    "               solution.target_dir, train=False, print_model=False)\n",
    "print(solution.dg_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 3.1, Misclassifications (2p)\n",
    "- Report the test score (on the held-out test data)\n",
    "    - Should be similar to score of previous model\n",
    "- Plot confusion matrix, discuss which classes are often confused.\n",
    "    - class 1 and 2 are most often confused\n",
    "- Visualize the misclassifications in more depth by focusing on a single class\n",
    "- Analyse which kinds of mistakes are made for that class.\n",
    "    - Should contain some insight (e.g. misclassifications when the numbers are curly or noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n",
      "Test score: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print_answer(solution.answer_q_3_1)\n",
    "if hasattr(solution, 'test_accuracy_3_1'):\n",
    "    try:\n",
    "        print(\"Test score: {:.2f}%\".format(solution.test_accuracy_3_1))\n",
    "    except TypeError:\n",
    "        print(\"Test score:\",solution.test_accuracy_3_1)\n",
    "else:\n",
    "    print(\"Test score NOT FOUND: test_accuracy_3_1 missing\")\n",
    "try:\n",
    "    solution.plot_confusion_matrix()\n",
    "except:\n",
    "    print(\"ERROR, could not build confusion matrix. Please check original report\")\n",
    "try:\n",
    "    solution.plot_misclassifications()\n",
    "except:\n",
    "    print(\"ERROR, could not build misclassification plot. Please check original report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 3.2, Activations (4p)\n",
    "- Retrieve and visualize the activations for one example\n",
    "- For every filter for different convolutional layers (at different depths in the network).\n",
    "- Give an explanation. Is your model indeed learning something useful?\n",
    "    - Should detect edges etc in first layers, higher-order object (e.g. interesting regions) in deeper layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_answer(solution.answer_q_3_2)\n",
    "try:\n",
    "    solution.plot_activations()\n",
    "except:\n",
    "    print(\"ERROR, could not build activation plot. Please check original report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 3.3, Class activation map (4p)\n",
    "- Show a class activation map for your last convolutional layer\n",
    "- Superimpose the activation map over the image, or plot side by side\n",
    "    - Should make sense, detect interesting regions to classify the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mdef\u001b[0m \u001b[0mplot_3_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    solution.plot_3_3()\n",
    "except:\n",
    "    print(\"ERROR, could not build class activation plot. Please check original report\")\n",
    "if hasattr(solution, 'plot_activation_map'):\n",
    "    %psource solution.plot_activation_map\n",
    "else:\n",
    "    %psource solution.plot_3_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 4.1, Fast feature extraction (5p)\n",
    "- Import the VGG16 model, pretrained on ImageNet\n",
    "- Freeze convolutional base, adds a dense layer\n",
    "- Consider unfreezing the last few convolutional layers and evaluate whether that works better\n",
    "    - Check if they do. It is very likely to help.\n",
    "- Discuss the observed performance\n",
    "    - Should get around 80% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n",
      "\u001b[91mNo model is returned by the model_builder\u001b[0m\n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mbuild_model_4_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print_answer(solution.answer_q_4_1)\n",
    "run_evaluation(\"model_4_1\", solution.build_model_4_1, solution.evaluation_split, solution.base_dir, \n",
    "               solution.target_dir, train=False)\n",
    "%psource solution.build_model_4_1\n",
    "if os.path.exists(os.path.join(solution.target_dir,'model_4_1.png')):\n",
    "    display(Image(os.path.join(solution.target_dir,'model_4_1.png'), width=200))\n",
    "#solution.build_model_4_1().layers[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 4.2, Embeddings (5p)\n",
    "- Generate embeddings with the trained convolutional part of model_4_1 (without the dense layer)\n",
    "- Embed the training and test data and store them to disk\n",
    "- Build and evaluate a pipeline on the embedded data\n",
    "    - Check if pipeline makes sense (e.g. use models that can handle many dimensions)\n",
    "- Describe what you did and what you observed (max 800 chars).\n",
    "    - Consider different models, preprocessing, tuning, etc.\n",
    "    - Check performance (see original Submission.html) when in doubt. We did not run all the evaluations because it takes too long, and the output is ill-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer  (length: 13)\n",
      "\n",
      "None\n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mstore_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\" Stores all necessary embeddings to file\u001b[0m\n",
      "\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mevaluation_4_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\" Runs 'evaluate_pipeline' with embedded versions of the input data \u001b[0m\n",
      "\u001b[0;34m  and returns the accuracy.\u001b[0m\n",
      "\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_answer(solution.answer_q_4_2)\n",
    "print(solution.generate_pipeline())\n",
    "#print(\"Evaluation:\",solution.evaluation_4_2(solution.X_train, solution.y_train, solution.X_test, solution.y_test))\n",
    "%psource solution.store_embeddings\n",
    "%psource solution.evaluation_4_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 0.29 seconds\n",
      "Last modified: May 26, 2020\n",
      "scikit-learn version: 0.23.1\n"
     ]
    }
   ],
   "source": [
    "end_verify = time.time()\n",
    "print(\"Running time: {:.2f} seconds\".format(end_verify - start_verify))\n",
    "print(\"Last modified: {}\".format(solution.last_edit))\n",
    "print(\"scikit-learn version: {0}\".format(solution.sklearn_version))\n",
    "\n",
    "with open(solution.grade_file, \"a\") as myfile:\n",
    "    myfile.write(','.join(grades)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2f29dc6c66354114b85885dfd6777f74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3aae203e8cc84ac29e650af4e378a469": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_a207fbe723b847afb5dac27a3f083324",
       "msg_id": "",
       "outputs": []
      }
     },
     "559dc08222bb429e80fd764fddc7e199": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [
        "widget-interact"
       ],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9fbf50daf03045fb98da8e14566b6791",
        "IPY_MODEL_3aae203e8cc84ac29e650af4e378a469"
       ],
       "layout": "IPY_MODEL_2f29dc6c66354114b85885dfd6777f74"
      }
     },
     "598fb66bb3fe48b4a0934eba2aaf1875": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "IntSliderView",
       "continuous_update": true,
       "description": "layer_index",
       "description_tooltip": null,
       "disabled": false,
       "layout": "IPY_MODEL_bb3c9cf5cd3241219bfdcdcff8dacef9",
       "max": 6,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_787df8b9e32d42f2bc62c3a60b03e474",
       "value": 0
      }
     },
     "66aff1143f584e7aa4f0d3ac8f13f53a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "745470c4642d431ebf144f3f0fce85f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "787df8b9e32d42f2bc62c3a60b03e474": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": "",
       "handle_color": null
      }
     },
     "8ea5477b1cfa44e992a32e9f20980d49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95fb406702164eefbf10476c62dfc9f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [
        "widget-interact"
       ],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_598fb66bb3fe48b4a0934eba2aaf1875",
        "IPY_MODEL_f312d1a6649e419395c38912b2f0f377"
       ],
       "layout": "IPY_MODEL_66aff1143f584e7aa4f0d3ac8f13f53a"
      }
     },
     "9fbf50daf03045fb98da8e14566b6791": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "IntSliderView",
       "continuous_update": true,
       "description": "focus_class",
       "description_tooltip": null,
       "disabled": false,
       "layout": "IPY_MODEL_745470c4642d431ebf144f3f0fce85f5",
       "max": 9,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_ca203bb70e734df4bdb3607522b6405c",
       "value": 0
      }
     },
     "a207fbe723b847afb5dac27a3f083324": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb3c9cf5cd3241219bfdcdcff8dacef9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ca203bb70e734df4bdb3607522b6405c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": "",
       "handle_color": null
      }
     },
     "f312d1a6649e419395c38912b2f0f377": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_8ea5477b1cfa44e992a32e9f20980d49",
       "msg_id": "",
       "outputs": []
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
